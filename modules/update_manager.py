"""
Ù…Ø¯ÙŠØ± Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª - Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© ÙˆØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
"""
import json
import os
import zipfile
import shutil
import hashlib
import tempfile
from datetime import datetime
from pathlib import Path

class UpdateManager:
    def __init__(self):
        self.updates_dir = "updates"
        self.updates_data_file = "data/updates_data.json"
        self.current_version = "3.0.0"
        self.developer_code = "01018"

        # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ù…ÙŠØ© Ø§Ù„ØªÙŠ Ù„Ù† ÙŠØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡Ø§
        self.protected_files = {
            "data/users_data.json",
            "data/people.json", 
            "data/moderators.json",
            "data/positions_data.json",
            "data/user_locations.json",
            "data/auto_dance_users.json",
            "data/room_permissions.json"
        }

        # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ÙŠÙØ³Ù…Ø­ Ø¨ØªØ­Ø¯ÙŠØ«Ù‡Ø§
        self.updatable_files = {
            "main.py",
            "run.py",
            "modules/",
            "templates/",
            "static/",
            "data/emotes_data.json",
            "data/emote_timings.json"
        }

        self.ensure_directories()
        self.load_updates_data()
        print("ğŸ”„ Ù…Ø¯ÙŠØ± Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø¬Ø§Ù‡Ø²")

    def ensure_directories(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"""
        os.makedirs(self.updates_dir, exist_ok=True)
        os.makedirs("data", exist_ok=True)
        os.makedirs("backups", exist_ok=True)

    def load_updates_data(self):
        """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª"""
        try:
            if os.path.exists(self.updates_data_file):
                with open(self.updates_data_file, 'r', encoding='utf-8') as f:
                    self.updates_data = json.load(f)
            else:
                self.updates_data = {
                    "current_version": self.current_version,
                    "updates": [],
                    "installed_updates": [],
                    "last_check": None
                }
                self.save_updates_data()
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª: {e}")
            self.updates_data = {
                "current_version": self.current_version,
                "updates": [],
                "installed_updates": [],
                "last_check": None
            }

    def save_updates_data(self):
        """Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª"""
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
            os.makedirs(os.path.dirname(self.updates_data_file), exist_ok=True)

            # Ø¥Ø¶Ø§ÙØ© timestamp Ù„Ù„Ø­ÙØ¸
            self.updates_data["last_saved"] = datetime.now().isoformat()

            with open(self.updates_data_file, 'w', encoding='utf-8') as f:
                json.dump(self.updates_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª - Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹: {len(self.updates_data.get('updates', []))}")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª: {e}")

    def verify_developer_code(self, code: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙƒÙˆØ¯ Ø§Ù„Ù…Ø·ÙˆØ±"""
        return code == self.developer_code

    def upload_update(self, file_path: str, version: str, title: str, description: str, changelog: str = "") -> dict:
        """Ø±ÙØ¹ ØªØ­Ø¯ÙŠØ« Ø¬Ø¯ÙŠØ¯"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
            if not os.path.exists(file_path):
                return {"success": False, "error": "Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ù„Ù
            if not zipfile.is_zipfile(file_path):
                return {"success": False, "error": "Ø§Ù„Ù…Ù„Ù Ù„ÙŠØ³ Ù…Ù„Ù ZIP ØµØ­ÙŠØ­"}

            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
            self.ensure_directories()

            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø±Ù ÙØ±ÙŠØ¯ Ù„Ù„ØªØ­Ø¯ÙŠØ«
            timestamp = int(datetime.now().timestamp())
            update_id = f"update_{version.replace('.', '_')}_{timestamp}"

            # Ù†Ø³Ø® Ø§Ù„Ù…Ù„Ù Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª
            update_file_path = os.path.join(self.updates_dir, f"{update_id}.zip")
            shutil.copy2(file_path, update_file_path)

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ø¬Ø§Ø­ Ø§Ù„Ù†Ø³Ø®
            if not os.path.exists(update_file_path):
                return {"success": False, "error": "ÙØ´Ù„ ÙÙŠ Ù†Ø³Ø® Ù…Ù„Ù Ø§Ù„ØªØ­Ø¯ÙŠØ«"}

            # Ø­Ø³Ø§Ø¨ hash Ø§Ù„Ù…Ù„Ù
            file_hash = self.calculate_file_hash(update_file_path)
            file_size = os.path.getsize(update_file_path)

            # Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ø¯ÙŠØ«
            update_data = {
                "id": update_id,
                "version": version,
                "title": title,
                "description": description,
                "changelog": changelog,
                "file_path": update_file_path,
                "file_hash": file_hash,
                "size": self.format_file_size(file_size),
                "size_bytes": file_size,
                "release_date": datetime.now().isoformat(),
                "is_active": True,
                "upload_timestamp": timestamp
            }

            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù„Ù„Ù‚Ø§Ø¦Ù…Ø©
            if "updates" not in self.updates_data:
                self.updates_data["updates"] = []

            self.updates_data["updates"].append(update_data)

            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            self.save_updates_data()

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if not os.path.exists(self.updates_data_file):
                return {"success": False, "error": "ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ø¯ÙŠØ«"}

            print(f"âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„ØªØ­Ø¯ÙŠØ« {version} Ø¨Ù†Ø¬Ø§Ø­ - ID: {update_id}")
            print(f"ğŸ“ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù: {update_file_path}")
            print(f"ğŸ“Š Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: {self.format_file_size(file_size)}")

            return {
                "success": True, 
                "update_id": update_id,
                "message": f"ØªÙ… Ø±ÙØ¹ Ø§Ù„ØªØ­Ø¯ÙŠØ« {version} Ø¨Ù†Ø¬Ø§Ø­"
            }

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø±ÙØ¹ Ø§Ù„ØªØ­Ø¯ÙŠØ«: {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e)}

    def get_available_updates(self) -> list:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©"""
        try:
            available_updates = []
            installed_ids = [u["id"] for u in self.updates_data.get("installed_updates", [])]

            for update in self.updates_data.get("updates", []):
                if update["is_active"] and update["id"] not in installed_ids:
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
                    if os.path.exists(update["file_path"]):
                        available_updates.append(update)
                    else:
                        update["is_active"] = False

            # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥ØµØ¯Ø§Ø± (Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ø§Ù‹)
            available_updates.sort(key=lambda x: x["release_date"], reverse=True)

            self.updates_data["last_check"] = datetime.now().isoformat()
            self.save_updates_data()

            return available_updates

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª: {e}")
            return []

    def apply_update(self, update_id: str) -> dict:
        """ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ø¯ÙŠØ« Ù…Ø¹ÙŠÙ† - Ù…ØªØ§Ø­ Ù„Ù„Ø¬Ù…ÙŠØ¹"""
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªØ­Ø¯ÙŠØ«
            update = None
            for u in self.updates_data.get("updates", []):
                if u["id"] == update_id:
                    update = u
                    break

            if not update:
                return {"success": False, "error": "Ø§Ù„ØªØ­Ø¯ÙŠØ« ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}

            if not os.path.exists(update["file_path"]):
                return {"success": False, "error": "Ù…Ù„Ù Ø§Ù„ØªØ­Ø¯ÙŠØ« ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† hash Ø§Ù„Ù…Ù„Ù
            current_hash = self.calculate_file_hash(update["file_path"])
            if current_hash != update["file_hash"]:
                return {"success": False, "error": "Ù…Ù„Ù Ø§Ù„ØªØ­Ø¯ÙŠØ« ØªØ§Ù„Ù"}

            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            backup_result = self.create_backup()
            if not backup_result["success"]:
                return {"success": False, "error": f"ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_result['error']}"}

            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ«
            update_result = self.extract_and_apply_update(update["file_path"])
            if not update_result["success"]:
                # Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
                self.restore_backup(backup_result["backup_path"])
                return {"success": False, "error": f"ÙØ´Ù„ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ«: {update_result['error']}"}

            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªØ­Ø¯ÙŠØ« ÙƒÙ…Ø·Ø¨Ù‚
            self.updates_data["installed_updates"].append({
                "id": update["id"],
                "version": update["version"],
                "installed_date": datetime.now().isoformat(),
                "backup_path": backup_result["backup_path"]
            })

            self.updates_data["current_version"] = update["version"]
            self.save_updates_data()

            print(f"âœ… ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ« {update['version']} Ø¨Ù†Ø¬Ø§Ø­")
            return {"success": True, "message": "ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¨Ù†Ø¬Ø§Ø­"}

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ«: {e}")
            return {"success": False, "error": str(e)}

    def create_backup(self) -> dict:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©"""
        try:
            backup_dir = "backups"
            os.makedirs(backup_dir, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"backup_{timestamp}.zip"
            backup_path = os.path.join(backup_dir, backup_name)

            with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as backup_zip:
                # Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ­Ø¯ÙŠØ« ÙÙ‚Ø·
                for updatable_path in self.updatable_files:
                    if os.path.exists(updatable_path):
                        if os.path.isfile(updatable_path):
                            backup_zip.write(updatable_path)
                        elif os.path.isdir(updatable_path):
                            for root, dirs, files in os.walk(updatable_path):
                                for file in files:
                                    file_path = os.path.join(root, file)
                                    backup_zip.write(file_path)

            print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_path}")
            return {"success": True, "backup_path": backup_path}

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")
            return {"success": False, "error": str(e)}

    def extract_and_apply_update(self, update_file_path: str) -> dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØªØ·Ø¨ÙŠÙ‚ Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…"""
        try:
            update_summary = {
                "new_files": [],
                "updated_files": [],
                "new_features": [],
                "changes_detected": []
            }

            with zipfile.ZipFile(update_file_path, 'r') as update_zip:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„Ù…Ø¬Ù„Ø¯ Ù…Ø¤Ù‚Øª Ø£ÙˆÙ„Ø§Ù‹
                with tempfile.TemporaryDirectory() as temp_dir:
                    print(f"ğŸ” ÙÙƒ Ø¶ØºØ· Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¥Ù„Ù‰: {temp_dir}")
                    update_zip.extractall(temp_dir)

                    # ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙŠØ§Øª Ø§Ù„ØªØ­Ø¯ÙŠØ«
                    self._analyze_update_contents(temp_dir, update_summary)

                    # Ù†Ø³Ø® Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨ØªØ­Ø¯ÙŠØ«Ù‡Ø§ ÙÙ‚Ø·
                    for root, dirs, files in os.walk(temp_dir):
                        for file in files:
                            source_path = os.path.join(root, file)
                            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ø³Ø¨ÙŠ
                            rel_path = os.path.relpath(source_path, temp_dir)

                            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ù Ù…Ø³Ù…ÙˆØ­ Ø¨ØªØ­Ø¯ÙŠØ«Ù‡
                            if self.is_file_updatable(rel_path):
                                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù Ø³Ø§Ø¨Ù‚Ø§Ù‹
                                if os.path.exists(rel_path):
                                    update_summary["updated_files"].append(rel_path)
                                    print(f"ğŸ”„ ØªØ­Ø¯ÙŠØ«: {rel_path}")
                                else:
                                    update_summary["new_files"].append(rel_path)
                                    print(f"âœ¨ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯: {rel_path}")

                                # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
                                dest_dir = os.path.dirname(rel_path)
                                if dest_dir:
                                    os.makedirs(dest_dir, exist_ok=True)

                                # Ù†Ø³Ø® Ø§Ù„Ù…Ù„Ù
                                shutil.copy2(source_path, rel_path)

            # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ø¯ÙŠØ«
            self._create_update_report(update_summary)

            return {
                "success": True, 
                "summary": update_summary,
                "report": self._format_update_summary(update_summary)
            }

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªØ­Ø¯ÙŠØ«: {e}")
            return {"success": False, "error": str(e)}

    def _analyze_update_contents(self, temp_dir: str, summary: dict):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙŠØ§Øª Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©"""
        try:
            print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙŠØ§Øª Ø§Ù„ØªØ­Ø¯ÙŠØ«...")

            for root, dirs, files in os.walk(temp_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    rel_path = os.path.relpath(file_path, temp_dir)

                    if file.endswith('.py'):
                        self._analyze_python_file(file_path, rel_path, summary)
                    elif file.endswith('.html'):
                        self._analyze_html_file(file_path, rel_path, summary)
                    elif file.endswith('.js'):
                        self._analyze_js_file(file_path, rel_path, summary)

        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ­Ø¯ÙŠØ«: {e}")

    def _analyze_python_file(self, file_path: str, rel_path: str, summary: dict):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª Python Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙˆØ§Ù…Ø± Ø¬Ø¯ÙŠØ¯Ø©
            import re

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙˆØ§Ù…Ø± elif message == 
            command_patterns = re.findall(r'elif message == ["\']([^"\']+)["\']', content)
            if command_patterns:
                for cmd in command_patterns:
                    summary["new_features"].append(f"ğŸ¯ Ø£Ù…Ø± Ø¬Ø¯ÙŠØ¯: {cmd} ÙÙŠ {rel_path}")

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¯ÙˆØ§Ù„ Ø¬Ø¯ÙŠØ¯Ø©
            function_patterns = re.findall(r'def ([a-zA-Z_][a-zA-Z0-9_]*)\(', content)
            if function_patterns:
                for func in function_patterns:
                    if not func.startswith('_'):  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø®Ø§ØµØ©
                        summary["new_features"].append(f"ğŸ”§ Ø¯Ø§Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø©: {func}() ÙÙŠ {rel_path}")

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ø§Ø³Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
            class_patterns = re.findall(r'class ([A-Z][a-zA-Z0-9_]*)', content)
            if class_patterns:
                for cls in class_patterns:
                    summary["new_features"].append(f"ğŸ“¦ ÙƒÙ„Ø§Ø³ Ø¬Ø¯ÙŠØ¯: {cls} ÙÙŠ {rel_path}")

        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù Python {rel_path}: {e}")

    def _analyze_html_file(self, file_path: str, rel_path: str, summary: dict):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª HTML Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† ØµÙØ­Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„ØµÙØ­Ø§Øª
            import re
            title_match = re.search(r'<title>([^<]+)</title>', content)
            if title_match:
                title = title_match.group(1)
                summary["new_features"].append(f"ğŸŒ ØµÙØ­Ø© Ø¬Ø¯ÙŠØ¯Ø©: {title} ({rel_path})")

        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù HTML {rel_path}: {e}")

    def _analyze_js_file(self, file_path: str, rel_path: str, summary: dict):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª JavaScript Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† ÙˆØ¸Ø§Ø¦Ù Ø¬Ø¯ÙŠØ¯Ø©"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¯ÙˆØ§Ù„ JavaScript
            import re
            function_patterns = re.findall(r'function ([a-zA-Z_][a-zA-Z0-9_]*)\(', content)
            if function_patterns:
                for func in function_patterns:
                    summary["new_features"].append(f"âš™ï¸ Ø¯Ø§Ù„Ø© JS Ø¬Ø¯ÙŠØ¯Ø©: {func}() ÙÙŠ {rel_path}")

        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù JS {rel_path}: {e}")

    def _create_update_report(self, summary: dict):
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„ Ø¹Ù† Ø§Ù„ØªØ­Ø¯ÙŠØ«"""
        try:
            report_path = f"updates/update_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            os.makedirs("updates", exist_ok=True)

            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("ğŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ\n")
                f.write("=" * 50 + "\n")
                f.write(f"â° ÙˆÙ‚Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

                f.write(f"ğŸ“ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ({len(summary['new_files'])}):\n")
                for file in summary['new_files']:
                    f.write(f"  + {file}\n")
                f.write("\n")

                f.write(f"ğŸ”„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ø¯Ø«Ø© ({len(summary['updated_files'])}):\n")
                for file in summary['updated_files']:
                    f.write(f"  ~ {file}\n")
                f.write("\n")

                f.write(f"âœ¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ({len(summary['new_features'])}):\n")
                for feature in summary['new_features']:
                    f.write(f"  {feature}\n")
                f.write("\n")

            print(f"ğŸ“„ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ø¯ÙŠØ«: {report_path}")

        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ø¯ÙŠØ«: {e}")

    def _format_update_summary(self, summary: dict) -> str:
        """ØªÙ†Ø³ÙŠÙ‚ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù„Ù„Ø¹Ø±Ø¶"""
        lines = ["ğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ø¯ÙŠØ«:"]

        if summary["new_files"]:
            lines.append(f"ğŸ“ Ù…Ù„ÙØ§Øª Ø¬Ø¯ÙŠØ¯Ø©: {len(summary['new_files'])}")

        if summary["updated_files"]:
            lines.append(f"ğŸ”„ Ù…Ù„ÙØ§Øª Ù…Ø­Ø¯Ø«Ø©: {len(summary['updated_files'])}")

        if summary["new_features"]:
            lines.append(f"âœ¨ Ù…ÙŠØ²Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©: {len(summary['new_features'])}")
            lines.append("ğŸ¯ Ø£Ù‡Ù… Ø§Ù„Ø¥Ø¶Ø§ÙØ§Øª:")
            for feature in summary["new_features"][:5]:  # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 Ù…ÙŠØ²Ø§Øª
                lines.append(f"  â€¢ {feature}")

        return "\n".join(lines)

    def is_file_updatable(self, file_path: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥Ù…ÙƒØ§Ù†ÙŠØ© ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù„Ù"""
        # ØªØ­ÙˆÙŠÙ„ Ù…Ø³Ø§Ø±Ø§Øª Windows Ù„Ù€ Unix
        file_path = file_path.replace('\\', '/')

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ù…ÙŠØ©
        if file_path in self.protected_files:
            return False

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ÙˆØ§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨ØªØ­Ø¯ÙŠØ«Ù‡Ø§
        for updatable in self.updatable_files:
            if file_path.startswith(updatable) or file_path == updatable:
                return True

        return False

    def restore_backup(self, backup_path: str) -> dict:
        """Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        try:
            if not os.path.exists(backup_path):
                return {"success": False, "error": "Ù…Ù„Ù Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}

            with zipfile.ZipFile(backup_path, 'r') as backup_zip:
                backup_zip.extractall('.')

            print(f"âœ… ØªÙ… Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù†: {backup_path}")
            return {"success": True}

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")
            return {"success": False, "error": str(e)}

    def calculate_file_hash(self, file_path: str) -> str:
        """Ø­Ø³Ø§Ø¨ hash Ù„Ù„Ù…Ù„Ù"""
        try:
            hash_sha256 = hashlib.sha256()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_sha256.update(chunk)
            return hash_sha256.hexdigest()
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ hash Ø§Ù„Ù…Ù„Ù: {e}")
            return ""

    def format_file_size(self, size_bytes: int) -> str:
        """ØªÙ†Ø³ÙŠÙ‚ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù"""
        try:
            if size_bytes == 0:
                return "0 Ø¨Ø§ÙŠØª"

            size_names = ["Ø¨Ø§ÙŠØª", "ÙƒÙŠÙ„ÙˆØ¨Ø§ÙŠØª", "Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª", "Ø¬ÙŠØ¬Ø§Ø¨Ø§ÙŠØª"]
            i = 0
            while size_bytes >= 1024.0 and i < len(size_names) - 1:
                size_bytes /= 1024.0
                i += 1

            return f"{size_bytes:.1f} {size_names[i]}"
        except:
            return "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"

    def get_system_info(self) -> dict:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
        try:
            return {
                "current_version": self.updates_data.get("current_version", self.current_version),
                "total_updates": len(self.updates_data.get("updates", [])),
                "installed_updates": len(self.updates_data.get("installed_updates", [])),
                "last_check": self.updates_data.get("last_check"),
                "last_update": self.get_last_installed_update()
            }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…: {e}")
            return {}

    def get_last_installed_update(self) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ù…Ø«Ø¨Øª"""
        try:
            installed = self.updates_data.get("installed_updates", [])
            if installed:
                last_update = max(installed, key=lambda x: x.get("installed_date", ""))
                return last_update.get("installed_date", "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")
            return "Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¨Ø¹Ø¯"
        except:
            return "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"

    def extract_zip_file(self, zip_path: str, extract_to: str = None, password: str = None) -> dict:
        """ÙÙƒ Ø¶ØºØ· Ù…Ù„Ù ZIP Ù…Ø¹ Ø¥Ù…ÙƒØ§Ù†ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø©"""
        try:
            if extract_to is None:
                extract_to = os.path.splitext(zip_path)[0]

            if not os.path.exists(zip_path):
                return {"success": False, "error": "Ù…Ù„Ù ZIP ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}

            if not zipfile.is_zipfile(zip_path):
                return {"success": False, "error": "Ø§Ù„Ù…Ù„Ù Ù„ÙŠØ³ Ù…Ù„Ù ZIP ØµØ­ÙŠØ­"}

            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬
            os.makedirs(extract_to, exist_ok=True)

            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ±
                if password:
                    zip_ref.setpassword(password.encode())

                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù„ÙØ§Øª
                file_list = zip_ref.namelist()

                # ÙÙƒ Ø§Ù„Ø¶ØºØ·
                zip_ref.extractall(extract_to)

                print(f"âœ… ØªÙ… ÙÙƒ Ø¶ØºØ· {len(file_list)} Ù…Ù„Ù Ø¥Ù„Ù‰: {extract_to}")

                return {
                    "success": True,
                    "extract_path": extract_to,
                    "files_extracted": len(file_list),
                    "file_list": file_list
                }

        except zipfile.BadZipFile:
            return {"success": False, "error": "Ù…Ù„Ù ZIP ØªØ§Ù„Ù"}
        except RuntimeError as e:
            if "Bad password" in str(e):
                return {"success": False, "error": "ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ± Ø®Ø§Ø·Ø¦Ø©"}
            return {"success": False, "error": f"Ø®Ø·Ø£ ÙÙŠ ÙÙƒ Ø§Ù„Ø¶ØºØ·: {str(e)}"}
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙÙƒ Ø¶ØºØ· Ø§Ù„Ù…Ù„Ù: {e}")
            return {"success": False, "error": str(e)}

    def create_zip_file(self, source_path: str, zip_path: str, compression_level: int = 6) -> dict:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ZIP Ù…Ù† Ù…Ø¬Ù„Ø¯ Ø£Ùˆ Ù…Ù„Ù"""
        try:
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=compression_level) as zip_ref:
                if os.path.isfile(source_path):
                    # Ù…Ù„Ù ÙˆØ§Ø­Ø¯
                    zip_ref.write(source_path, os.path.basename(source_path))
                    files_added = 1
                elif os.path.isdir(source_path):
                    # Ù…Ø¬Ù„Ø¯ ÙƒØ§Ù…Ù„
                    files_added = 0
                    for root, dirs, files in os.walk(source_path):
                        for file in files:
                            file_path = os.path.join(root, file)
                            arcname = os.path.relpath(file_path, source_path)
                            zip_ref.write(file_path, arcname)
                            files_added += 1
                else:
                    return {"success": False, "error": "Ø§Ù„Ù…Ø³Ø§Ø± ØºÙŠØ± ØµØ­ÙŠØ­"}

            file_size = self.format_file_size(os.path.getsize(zip_path))
            print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ZIP: {zip_path} ({file_size})")

            return {
                "success": True,
                "zip_path": zip_path,
                "files_added": files_added,
                "size": file_size
            }

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ZIP: {e}")
            return {"success": False, "error": str(e)}

    def list_zip_contents(self, zip_path: str) -> dict:
        """Ø¹Ø±Ø¶ Ù…Ø­ØªÙˆÙŠØ§Øª Ù…Ù„Ù ZIP Ø¯ÙˆÙ† ÙÙƒ Ø§Ù„Ø¶ØºØ·"""
        try:
            if not zipfile.is_zipfile(zip_path):
                return {"success": False, "error": "Ø§Ù„Ù…Ù„Ù Ù„ÙŠØ³ Ù…Ù„Ù ZIP ØµØ­ÙŠØ­"}

            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                file_info = []
                total_size = 0
                compressed_size = 0

                for info in zip_ref.infolist():
                    file_info.append({
                        "filename": info.filename,
                        "size": info.file_size,
                        "compressed_size": info.compress_size,
                        "date_time": datetime(*info.date_time).isoformat() if info.date_time else None,
                        "is_dir": info.is_dir()
                    })
                    total_size += info.file_size
                    compressed_size += info.compress_size

                compression_ratio = ((total_size - compressed_size) / total_size * 100) if total_size > 0 else 0

                return {
                    "success": True,
                    "files": file_info,
                    "total_files": len(file_info),
                    "total_size": self.format_file_size(total_size),
                    "compressed_size": self.format_file_size(compressed_size),
                    "compression_ratio": f"{compression_ratio:.1f}%"
                }

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ø­ØªÙˆÙŠØ§Øª ZIP: {e}")
            return {"success": False, "error": str(e)}

    def extract_specific_files(self, zip_path: str, file_patterns: list, extract_to: str = None) -> dict:
        """ÙÙƒ Ø¶ØºØ· Ù…Ù„ÙØ§Øª Ù…Ø¹ÙŠÙ†Ø© ÙÙ‚Ø· Ù…Ù† ZIP"""
        try:
            if extract_to is None:
                extract_to = "extracted_files"

            if not zipfile.is_zipfile(zip_path):
                return {"success": False, "error": "Ø§Ù„Ù…Ù„Ù Ù„ÙŠØ³ Ù…Ù„Ù ZIP ØµØ­ÙŠØ­"}

            os.makedirs(extract_to, exist_ok=True)
            extracted_files = []

            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                for file_info in zip_ref.infolist():
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù†Ù…Ø·
                    for pattern in file_patterns:
                        if pattern in file_info.filename or file_info.filename.endswith(pattern):
                            zip_ref.extract(file_info, extract_to)
                            extracted_files.append(file_info.filename)
                            break

            print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(extracted_files)} Ù…Ù„Ù Ù…ØªØ·Ø§Ø¨Ù‚")

            return {
                "success": True,
                "extracted_files": extracted_files,
                "extract_path": extract_to,
                "count": len(extracted_files)
            }

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©: {e}")
            return {"success": False, "error": str(e)}

    def validate_zip_integrity(self, zip_path: str) -> dict:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø³Ù„Ø§Ù…Ø© Ù…Ù„Ù ZIP"""
        try:
            if not zipfile.is_zipfile(zip_path):
                return {"success": False, "error": "Ø§Ù„Ù…Ù„Ù Ù„ÙŠØ³ Ù…Ù„Ù ZIP ØµØ­ÙŠØ­"}

            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                # Ø§Ø®ØªØ¨Ø§Ø± ÙƒÙ„ Ù…Ù„Ù
                corrupt_files = []
                tested_files = 0

                for file_info in zip_ref.infolist():
                    if not file_info.is_dir():
                        try:
                            # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
                            with zip_ref.open(file_info.filename) as f:
                                f.read()
                            tested_files += 1
                        except Exception as e:
                            corrupt_files.append({
                                "filename": file_info.filename,
                                "error": str(e)
                            })

                is_valid = len(corrupt_files) == 0

                return {
                    "success": True,
                    "is_valid": is_valid,
                    "tested_files": tested_files,
                    "corrupt_files": corrupt_files,
                    "status": "Ù…Ù„Ù Ø³Ù„ÙŠÙ…" if is_valid else f"ÙˆØ¬Ø¯ {len(corrupt_files)} Ù…Ù„Ù ØªØ§Ù„Ù"
                }

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø³Ù„Ø§Ù…Ø© ZIP: {e}")
            return {"success": False, "error": str(e)}

    def cleanup_old_backups(self, max_backups: int = 5):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        try:
            backup_dir = "backups"
            if not os.path.exists(backup_dir):
                return

            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            backup_files = []
            for file in os.listdir(backup_dir):
                if file.startswith("backup_") and file.endswith(".zip"):
                    file_path = os.path.join(backup_dir, file)
                    backup_files.append((file_path, os.path.getctime(file_path)))

            # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ (Ø§Ù„Ø£Ù‚Ø¯Ù… Ø£ÙˆÙ„Ø§Ù‹)
            backup_files.sort(key=lambda x: x[1])

            # Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
            while len(backup_files) > max_backups:
                old_backup = backup_files.pop(0)
                os.remove(old_backup[0])
                print(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù‚Ø¯ÙŠÙ…Ø©: {old_backup[0]}")

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")

    def auto_extract_and_apply_updates(self):
        """ÙØ­Øµ Ù…Ø¬Ù„Ø¯ updates ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ÙˆØªØ·Ø¨ÙŠÙ‚ Ø£ÙŠ ØªØ­Ø¯ÙŠØ«Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¹ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±"""
        try:
            updates_dir = "updates"
            if not os.path.exists(updates_dir):
                return None

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª ZIP Ø¬Ø¯ÙŠØ¯Ø©
            zip_files = [f for f in os.listdir(updates_dir) if f.endswith('.zip')]

            if not zip_files:
                return None

            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ù„ÙØ§Øª Ø­Ø³Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ (Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ø§Ù‹)
            zip_files_with_time = []
            for zip_file in zip_files:
                zip_path = os.path.join(updates_dir, zip_file)
                mod_time = os.path.getmtime(zip_path)
                zip_files_with_time.append((zip_file, mod_time, zip_path))

            zip_files_with_time.sort(key=lambda x: x[1], reverse=True)

            # ØªØ·Ø¨ÙŠÙ‚ Ø¢Ø®Ø± Ù…Ù„Ù ZIP
            latest_zip = zip_files_with_time[0]
            zip_filename = latest_zip[0]
            zip_path = latest_zip[2]

            print(f"ğŸ” ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù ØªØ­Ø¯ÙŠØ« Ø¬Ø¯ÙŠØ¯: {zip_filename}")

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù„Ù… ÙŠØªÙ… ØªØ·Ø¨ÙŠÙ‚Ù‡ Ù…Ù† Ù‚Ø¨Ù„
            applied_files = self.get_applied_local_updates()
            if zip_filename in applied_files:
                print(f"âš ï¸ Ø§Ù„Ù…Ù„Ù {zip_filename} ØªÙ… ØªØ·Ø¨ÙŠÙ‚Ù‡ Ù…Ø³Ø¨Ù‚Ø§Ù‹")
                return None

            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù…Ø¹ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
            result = self.auto_extract_and_apply_direct(zip_path, zip_filename)

            if result["success"]:
                print(f"âœ… ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙˆØ§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ù† {zip_filename}")
                return {
                    "filename": zip_filename,
                    "result": result,
                    "message": f"ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙˆØ§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ù† {zip_filename}"
                }
            else:
                print(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ: {result.get('error')}")
                return None

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙØ­Øµ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª: {e}")
            return None

    def auto_extract_and_apply_direct(self, zip_path: str, filename: str):
        """ÙÙƒ Ø¶ØºØ· ÙˆØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¯ÙˆÙ† Ù…Ø¬Ù„Ø¯Ø§Øª Ù…Ø¤Ù‚ØªØ©"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ù„Ù
            if not zipfile.is_zipfile(zip_path):
                return {"success": False, "error": "Ø§Ù„Ù…Ù„Ù Ù„ÙŠØ³ Ù…Ù„Ù ZIP ØµØ­ÙŠØ­"}

            print(f"ğŸ”„ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ù„ØªØ­Ø¯ÙŠØ«: {filename}")

            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            backup_result = self.create_backup()
            if not backup_result["success"]:
                return {"success": False, "error": f"ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_result['error']}"}

            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù…Ø¨Ø§Ø´Ø±Ø©
            update_result = self.extract_and_apply_update_direct(zip_path)

            if not update_result["success"]:
                # Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„
                self.restore_backup(backup_result["backup_path"])
                return {"success": False, "error": f"ÙØ´Ù„ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ«: {update_result['error']}"}

            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø·Ø¨Ù‚
            current_time = datetime.now().isoformat()
            local_update_data = {
                "id": f"auto_direct_update_{int(datetime.now().timestamp())}",
                "version": "ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù…Ø¨Ø§Ø´Ø±",
                "source": "ØªØ·Ø¨ÙŠÙ‚ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ù…Ø¬Ù„Ø¯ updates",
                "filename": filename,
                "applied_date": current_time,
                "backup_path": backup_result["backup_path"],
                "analysis": update_result.get("summary", {}),
                "report": update_result.get("report", ""),
                "auto_applied": True,
                "direct_application": True
            }

            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ù…Ø·Ø¨Ù‚Ø©
            if "installed_updates" not in self.updates_data:
                self.updates_data["installed_updates"] = []

            self.updates_data["installed_updates"].append(local_update_data)
            self.save_updates_data()

            print(f"âœ… ØªÙ… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ø¨Ù†Ø¬Ø§Ø­ Ù„Ù€ {filename}")

            return {
                "success": True,
                "message": f"ØªÙ… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ù† {filename}",
                "filename": filename,
                "backup_path": backup_result["backup_path"],
                "analysis": update_result.get("summary", {}),
                "report": update_result.get("report", ""),
                "direct_applied": True
            }

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ù„ØªØ­Ø¯ÙŠØ«: {e}")
            return {"success": False, "error": str(e)}

    def extract_and_apply_update_direct(self, update_file_path: str) -> dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØªØ·Ø¨ÙŠÙ‚ Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…"""
        try:
            update_summary = {
                "new_files": [],
                "updated_files": [],
                "new_features": [],
                "changes_detected": [],
                "total_applied": 0
            }

            print(f"ğŸ”„ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ø§Ù„Ù…Ù„Ù: {update_file_path}")

            with zipfile.ZipFile(update_file_path, 'r') as update_zip:
                # Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„Ù…Ø¬Ù„Ø¯ Ù…Ø¤Ù‚Øª
                for file_info in update_zip.infolist():
                    if file_info.is_dir():
                        continue

                    file_path = file_info.filename
                    # ØªØ­ÙˆÙŠÙ„ Ù…Ø³Ø§Ø±Ø§Øª Windows Ù„Ù€ Unix
                    file_path = file_path.replace('\\', '/')

                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ù Ù…Ø³Ù…ÙˆØ­ Ø¨ØªØ­Ø¯ÙŠØ«Ù‡
                    if self.is_file_updatable(file_path):
                        try:
                            # Ù‚Ø±Ø§Ø¡Ø© Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù Ù…Ù† ZIP
                            with update_zip.open(file_info) as source_file:
                                file_content = source_file.read()

                            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù Ø³Ø§Ø¨Ù‚Ø§Ù‹
                            if os.path.exists(file_path):
                                update_summary["updated_files"].append(file_path)
                                print(f"ğŸ”„ ØªØ­Ø¯ÙŠØ« Ù…Ø¨Ø§Ø´Ø±: {file_path}")
                            else:
                                update_summary["new_files"].append(file_path)
                                print(f"âœ¨ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ù…Ø¨Ø§Ø´Ø±: {file_path}")

                            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
                            dest_dir = os.path.dirname(file_path)
                            if dest_dir:
                                os.makedirs(dest_dir, exist_ok=True)

                            # ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„Ù Ù…Ø¨Ø§Ø´Ø±Ø©
                            with open(file_path, 'wb') as dest_file:
                                dest_file.write(file_content)

                            update_summary["total_applied"] += 1

                            # ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…ÙŠØ²Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
                            if file_path.endswith('.py'):
                                self._analyze_python_content(file_content.decode('utf-8', errors='ignore'), file_path, update_summary)

                        except Exception as file_error:
                            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ù„Ù {file_path}: {file_error}")
                            continue

            # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ø¯ÙŠØ«
            self._create_update_report_direct(update_summary)

            print(f"âœ… ØªÙ… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ù€ {update_summary['total_applied']} Ù…Ù„Ù")

            return {
                "success": True, 
                "summary": update_summary,
                "report": self._format_update_summary_direct(update_summary)
            }

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±: {e}")
            return {"success": False, "error": str(e)}

    def _analyze_python_content(self, content: str, file_path: str, summary: dict):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª Python Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©"""
        try:
            import re

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙˆØ§Ù…Ø± Ø¬Ø¯ÙŠØ¯Ø©
            command_patterns = re.findall(r'elif message == ["\']([^"\']+)["\']', content)
            for cmd in command_patterns:
                summary["new_features"].append(f"ğŸ¯ Ø£Ù…Ø± Ø¬Ø¯ÙŠØ¯: {cmd} ÙÙŠ {file_path}")

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¯ÙˆØ§Ù„ Ø¬Ø¯ÙŠØ¯Ø©
            function_patterns = re.findall(r'def ([a-zA-Z_][a-zA-Z0-9_]*)\(', content)
            for func in function_patterns:
                if not func.startswith('_'):
                    summary["new_features"].append(f"ğŸ”§ Ø¯Ø§Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø©: {func}() ÙÙŠ {file_path}")

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ø§Ø³Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
            class_patterns = re.findall(r'class ([A-Z][a-zA-Z0-9_]*)', content)
            for cls in class_patterns:
                summary["new_features"].append(f"ğŸ“¦ ÙƒÙ„Ø§Ø³ Ø¬Ø¯ÙŠØ¯: {cls} ÙÙŠ {file_path}")

        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Python {file_path}: {e}")

    def _create_update_report_direct(self, summary: dict):
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„ Ø¹Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±"""
        try:
            report_path = f"updates/direct_update_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            os.makedirs("updates", exist_ok=True)

            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("ğŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ù„ØªØ­Ø¯ÙŠØ«\n")
                f.write("=" * 50 + "\n")
                f.write(f"â° ÙˆÙ‚Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ğŸ”„ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚: Ù…Ø¨Ø§Ø´Ø±Ø© (Ø¨Ø¯ÙˆÙ† Ù…Ø¬Ù„Ø¯Ø§Øª Ù…Ø¤Ù‚ØªØ©)\n\n")

                f.write(f"ğŸ“ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ({len(summary['new_files'])}):\n")
                for file in summary['new_files']:
                    f.write(f"  + {file}\n")
                f.write("\n")

                f.write(f"ğŸ”„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ø¯Ø«Ø© ({len(summary['updated_files'])}):\n")
                for file in summary['updated_files']:
                    f.write(f"  ~ {file}\n")
                f.write("\n")

                f.write(f"âœ¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ© ({len(summary['new_features'])}):\n")
                for feature in summary['new_features']:
                    f.write(f"  {feature}\n")
                f.write("\n")

                f.write(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø·Ø¨Ù‚Ø©: {summary['total_applied']}\n")

            print(f"ğŸ“„ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±: {report_path}")

        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±: {e}")

    def _format_update_summary_direct(self, summary: dict) -> str:
        """ØªÙ†Ø³ÙŠÙ‚ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ù„Ø¹Ø±Ø¶"""
        lines = ["ğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±:"]

        lines.append(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø·Ø¨Ù‚Ø©: {summary['total_applied']}")

        if summary["new_files"]:
            lines.append(f"ğŸ“ Ù…Ù„ÙØ§Øª Ø¬Ø¯ÙŠØ¯Ø©: {len(summary['new_files'])}")

        if summary["updated_files"]:
            lines.append(f"ğŸ”„ Ù…Ù„ÙØ§Øª Ù…Ø­Ø¯Ø«Ø©: {len(summary['updated_files'])}")

        if summary["new_features"]:
            lines.append(f"âœ¨ Ù…ÙŠØ²Ø§Øª Ù…ÙƒØªØ´ÙØ©: {len(summary['new_features'])}")
            lines.append("ğŸ¯ Ø£Ù‡Ù… Ø§Ù„Ø¥Ø¶Ø§ÙØ§Øª:")
            for feature in summary["new_features"][:5]:
                lines.append(f"  â€¢ {feature}")

        lines.append("âš¡ ØªÙ… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¯ÙˆÙ† Ù…Ø¬Ù„Ø¯Ø§Øª Ù…Ø¤Ù‚ØªØ©")

        return "\n".join(lines)

    def apply_local_update_file(self, zip_path: str, filename: str):
        """ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ø¯ÙŠØ« Ù…Ø­Ù„ÙŠ Ù…Ù† Ù…Ù„Ù ZIP Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ù„Ù
            if not zipfile.is_zipfile(zip_path):
                return {"success": False, "error": "Ø§Ù„Ù…Ù„Ù Ù„ÙŠØ³ Ù…Ù„Ù ZIP ØµØ­ÙŠØ­"}

            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            backup_result = self.create_backup()
            if not backup_result["success"]:
                return {"success": False, "error": f"ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_result['error']}"}

            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù…Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
            update_result = self.extract_and_apply_update(zip_path)

            if not update_result["success"]:
                # Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„
                self.restore_backup(backup_result["backup_path"])
                return {"success": False, "error": f"ÙØ´Ù„ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ«: {update_result['error']}"}

            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø­Ù„ÙŠ Ù…Ø¹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            current_time = datetime.now().isoformat()
            local_update_data = {
                "id": f"auto_local_update_{int(datetime.now().timestamp())}",
                "version": "ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù…Ø­Ù„ÙŠ",
                "source": "ØªØ·Ø¨ÙŠÙ‚ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù…Ù† Ù…Ø¬Ù„Ø¯ updates",
                "filename": filename,
                "applied_date": current_time,
                "backup_path": backup_result["backup_path"],
                "analysis": update_result.get("summary", {}),
                "report": update_result.get("report", "")
            }

            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø­Ù„ÙŠ Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ù…Ø·Ø¨Ù‚Ø©
            if "installed_updates" not in self.updates_data:
                self.updates_data["installed_updates"] = []

            self.updates_data["installed_updates"].append(local_update_data)
            self.save_updates_data()

            return {
                "success": True,
                "message": f"ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù…Ù† {filename}",
                "filename": filename,
                "backup_path": backup_result["backup_path"],
                "analysis": update_result.get("summary", {}),
                "report": update_result.get("report", "")
            }

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø­Ù„ÙŠ: {e}")
            return {"success": False, "error": str(e)}

    def get_applied_local_updates(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø§Ù„Ù…Ø·Ø¨Ù‚Ø©"""
        try:
            applied_files = []
            installed_updates = self.updates_data.get("installed_updates", [])

            for update in installed_updates:
                filename = update.get("filename")
                if filename:
                    applied_files.append(filename)

            return applied_files
        except:
            return []

    def apply_local_update(self, zip_filename: str):
        """ÙÙƒ Ø¶ØºØ· ÙˆØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù ZIP (Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙŠØ¯ÙˆÙŠ)"""
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù…Ø¬Ù„Ø¯ updates Ø£Ùˆ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
            zip_paths = [
                f"updates/{zip_filename}",
                zip_filename,
                f"{zip_filename}.zip"
            ]

            zip_path = None
            for path in zip_paths:
                if os.path.exists(path):
                    zip_path = path
                    break

            if not zip_path:
                return f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù: {zip_filename}"

            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ«
            result = self.apply_local_update_file(zip_path, zip_filename)

            if result["success"]:
                info = f"âœ… {result['message']}\n"
                if result.get("report"):
                    info += f"\nğŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ø¯ÙŠØ«:\n{result['report']}"
                return info
            else:
                return f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ«: {result.get('error', 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}"

        except Exception as e:
            return f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ«: {str(e)}"

    def extract_to_custom_folder(self, zip_filename: str, folder_name: str = None):
        """ÙÙƒ Ø¶ØºØ· Ù…Ù„Ù ZIP ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø®Ø§Øµ Ø¯ÙˆÙ† ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø¯ÙŠØ«"""
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù…Ø¬Ù„Ø¯ backups Ø£Ùˆ updates Ø£Ùˆ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
            zip_paths = [
                f"backups/{zip_filename}",
                f"updates/{zip_filename}",
                zip_filename,
                f"backups/{zip_filename}.zip",
                f"updates/{zip_filename}.zip",
                f"{zip_filename}.zip"
            ]

            zip_path = None
            for path in zip_paths:
                if os.path.exists(path):
                    zip_path = path
                    break

            if not zip_path:
                return f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù: {zip_filename}"

            # ØªØ­Ø¯ÙŠØ¯ Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯
            if not folder_name:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø¨Ø¯ÙˆÙ† Ø§Ù…ØªØ¯Ø§Ø¯ Ù…Ø¹ timestamp
                base_name = os.path.splitext(os.path.basename(zip_filename))[0]
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                folder_name = f"extracted_{base_name}_{timestamp}"

            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬
            extract_path = f"extracted_files/{folder_name}"
            os.makedirs(extract_path, exist_ok=True)

            # ÙÙƒ Ø§Ù„Ø¶ØºØ· Ù…Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            analysis_result = self.extract_and_analyze_zip(zip_path, extract_path)

            if analysis_result["success"]:
                return f"""âœ… ØªÙ… ÙÙƒ Ø¶ØºØ· Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­!

ğŸ“ Ù…Ø³Ø§Ø± Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬: {extract_path}
ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª: {analysis_result['files_count']}
ğŸ“‚ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª: {analysis_result['folders_count']}
ğŸ’¾ Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {analysis_result['total_size']}

ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰:
{analysis_result['analysis_summary']}

ğŸ“ Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„Ù…Ù„ÙØ§Øª Ù…ÙØ³ØªØ®Ø±Ø¬Ø© ÙÙŠ Ù…Ø¬Ù„Ø¯ Ù…Ù†ÙØµÙ„ ÙˆÙ„Ù… ÙŠØªÙ… ØªØ·Ø¨ÙŠÙ‚Ù‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø§Ù…."""
            else:
                return f"âŒ ÙØ´Ù„ ÙÙŠ ÙÙƒ Ø§Ù„Ø¶ØºØ·: {analysis_result.get('error', 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}"

        except Exception as e:
            return f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙÙƒ Ø§Ù„Ø¶ØºØ·: {str(e)}"

    def extract_and_analyze_zip(self, zip_path: str, extract_path: str):
        """ÙÙƒ Ø¶ØºØ· ÙˆØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙŠØ§Øª Ù…Ù„Ù ZIP"""
        try:
            if not zipfile.is_zipfile(zip_path):
                return {"success": False, "error": "Ø§Ù„Ù…Ù„Ù Ù„ÙŠØ³ Ù…Ù„Ù ZIP ØµØ­ÙŠØ­"}

            analysis_summary = {
                "python_files": [],
                "html_files": [],
                "js_files": [],
                "json_files": [],
                "other_files": [],
                "new_features": []
            }

            files_count = 0
            folders_count = 0
            total_size = 0

            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
                zip_ref.extractall(extract_path)

                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª
                for file_info in zip_ref.infolist():
                    if file_info.is_dir():
                        folders_count += 1
                    else:
                        files_count += 1
                        total_size += file_info.file_size

                        # ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª
                        filename = file_info.filename.lower()
                        if filename.endswith('.py'):
                            analysis_summary["python_files"].append(file_info.filename)
                            # ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù Python
                            try:
                                with zip_ref.open(file_info) as f:
                                    content = f.read().decode('utf-8', errors='ignore')
                                    self._analyze_python_content_for_display(content, file_info.filename, analysis_summary)
                            except:
                                pass
                        elif filename.endswith(('.html', '.htm')):
                            analysis_summary["html_files"].append(file_info.filename)
                        elif filename.endswith('.js'):
                            analysis_summary["js_files"].append(file_info.filename)
                        elif filename.endswith('.json'):
                            analysis_summary["json_files"].append(file_info.filename)
                        else:
                            analysis_summary["other_files"].append(file_info.filename)

            # ØªÙ†Ø³ÙŠÙ‚ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            summary_text = self._format_analysis_summary(analysis_summary)

            return {
                "success": True,
                "files_count": files_count,
                "folders_count": folders_count,
                "total_size": self.format_file_size(total_size),
                "analysis_summary": summary_text,
                "extract_path": extract_path
            }

        except Exception as e:
            return {"success": False, "error": str(e)}

    def _analyze_python_content_for_display(self, content: str, file_path: str, summary: dict):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª Python Ù„Ù„Ø¹Ø±Ø¶"""
        try:
            import re

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙˆØ§Ù…Ø± Ø¬Ø¯ÙŠØ¯Ø©
            command_patterns = re.findall(r'elif message == ["\']([^"\']+)["\']', content)
            for cmd in command_patterns:
                summary["new_features"].append(f"ğŸ¯ Ø£Ù…Ø±: {cmd} ÙÙŠ {file_path}")

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¯ÙˆØ§Ù„ Ø¬Ø¯ÙŠØ¯Ø©
            function_patterns = re.findall(r'def ([a-zA-Z_][a-zA-Z0-9_]*)\(', content)
            for func in function_patterns[:5]:  # Ø£ÙˆÙ„ 5 Ø¯ÙˆØ§Ù„ ÙÙ‚Ø·
                if not func.startswith('_'):
                    summary["new_features"].append(f"ğŸ”§ Ø¯Ø§Ù„Ø©: {func}() ÙÙŠ {file_path}")

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ø§Ø³Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
            class_patterns = re.findall(r'class ([A-Z][a-zA-Z0-9_]*)', content)
            for cls in class_patterns:
                summary["new_features"].append(f"ğŸ“¦ ÙƒÙ„Ø§Ø³: {cls} ÙÙŠ {file_path}")

        except:
            pass

    def _format_analysis_summary(self, analysis: dict) -> str:
        """ØªÙ†Ø³ÙŠÙ‚ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù„Ù„Ø¹Ø±Ø¶"""
        lines = []

        if analysis["python_files"]:
            lines.append(f"ğŸ Ù…Ù„ÙØ§Øª Python: {len(analysis['python_files'])}")
            for file in analysis["python_files"][:3]:
                lines.append(f"   â€¢ {file}")
            if len(analysis["python_files"]) > 3:
                lines.append(f"   â€¢ ... Ùˆ {len(analysis['python_files']) - 3} Ù…Ù„Ù Ø¢Ø®Ø±")

        if analysis["html_files"]:
            lines.append(f"ğŸŒ Ù…Ù„ÙØ§Øª HTML: {len(analysis['html_files'])}")

        if analysis["js_files"]:
            lines.append(f"âš™ï¸ Ù…Ù„ÙØ§Øª JavaScript: {len(analysis['js_files'])}")

        if analysis["json_files"]:
            lines.append(f"ğŸ“„ Ù…Ù„ÙØ§Øª JSON: {len(analysis['json_files'])}")

        if analysis["other_files"]:
            lines.append(f"ğŸ“ Ù…Ù„ÙØ§Øª Ø£Ø®Ø±Ù‰: {len(analysis['other_files'])}")

        if analysis["new_features"]:
            lines.append(f"\nâœ¨ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
            for feature in analysis["new_features"][:8]:  # Ø£ÙˆÙ„ 8 Ù…ÙŠØ²Ø§Øª
                lines.append(f"   â€¢ {feature}")
            if len(analysis["new_features"]) > 8:
                lines.append(f"   â€¢ ... Ùˆ {len(analysis['new_features']) - 8} Ù…ÙŠØ²Ø© Ø£Ø®Ø±Ù‰")

        return "\n".join(lines) if lines else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªØ­Ù„ÙŠÙ„ Ù…ØªØ§Ø­Ø©"

    def list_extracted_folders(self):
        """Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…ÙØ³ØªØ®Ø±Ø¬Ø©"""
        try:
            extracted_dir = "extracted_files"
            if not os.path.exists(extracted_dir):
                return "âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¬Ù„Ø¯Ø§Øª Ù…ÙØ³ØªØ®Ø±Ø¬Ø©"

            folders = [f for f in os.listdir(extracted_dir) if os.path.isdir(os.path.join(extracted_dir, f))]

            if not folders:
                return "âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¬Ù„Ø¯Ø§Øª Ù…ÙØ³ØªØ®Ø±Ø¬Ø©"

            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø­Ø³Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ (Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ø§Ù‹)
            folders_with_time = []
            for folder in folders:
                folder_path = os.path.join(extracted_dir, folder)
                create_time = os.path.getctime(folder_path)
                folders_with_time.append((folder, create_time))

            folders_with_time.sort(key=lambda x: x[1], reverse=True)

            result = "ğŸ“ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…ÙØ³ØªØ®Ø±Ø¬Ø©:\n"
            for i, (folder, create_time) in enumerate(folders_with_time, 1):
                folder_path = os.path.join(extracted_dir, folder)
                
                # Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª
                file_count = 0
                for root, dirs, files in os.walk(folder_path):
                    file_count += len(files)

                # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªØ§Ø±ÙŠØ®
                create_date = datetime.fromtimestamp(create_time).strftime("%Y-%m-%d %H:%M")
                
                result += f"{i}. ğŸ“‚ {folder}\n"
                result += f"   ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡: {create_date}\n"
                result += f"   ğŸ“„ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª: {file_count}\n"

            return result.strip()

        except Exception as e:
            return f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª: {str(e)}"